---
title: "PSTAT131 Homework 2"
author: "Shivani Kharva"
date: "2022-10-03"
output: html_document
---

# Homework 2  

## Linear Regression  

**Reading in the data and loading it in**   
```{r}
abalone <- read.csv("abalone.csv")
library(tidyverse)
library(tidymodels)
```

### Question 1  

```{r}
# Adding age to dataset
age <- abalone$rings + 1.5
abalone2 <- cbind(abalone, age)

# Assessing distribution of age
age_dist <- ggplot(abalone2, aes(age)) +
  geom_histogram()
age_dist
```

The distribution of `age` is right skewed and unimodal. There is a peak in the data at around 11 years old.  

### Question 2  

```{r}
# Setting the seed
set.seed(0124)  

# Splitting the data
abalone_split <- initial_split(abalone2, prop = 0.80, strata = age)
abalone_train <- training(abalone_split)
abalone_test <- testing(abalone_split)
```

### Question 3  HELP
- take out rings?
- step_interact()
- step_center()
- step_scale()

We should not use `rings` to predict `age` because the `rings` variable would be able to give us the exact age by adding 1.5 to it. There would be no need to predict `age` if we could just directly calculate it using `rings`.  

```{r}
# Creating a recipe predicting the outcome variable, age

# Creating abalone training set without rings variable
abalone_train2 <- abalone_train[, !names(abalone_train) %in% c("rings")]

# Creating initial simple recipe (without rings variable)
simple_abalone_recipe <- recipe(age ~ ., data = abalone_train2)

# Creating the recipe
abalone_recipe <- recipe(age ~ ., data = abalone_train2) %>%
  # Dummy coding any categorical predictors
  step_dummy(all_nominal_predictors())
abalone_recipe %>%
  # Creating the interactions
  step_interact(terms = ~ type:shucked_weight) %>%
  step_interact(terms = ~ longest_shell:diameter) %>%
  step_interact(terms = ~ shucked_weight:shell_weight) %>%
  # Centering all predictors
  step_center(all_predictors()) %>%
  # Scaling all predictors
  step_scale(all_predictors())
```

### Question 4  

```{r}
# Creating and storing a linear regression object using lm engine
lm_model <- linear_reg() %>%
  set_engine("lm")
```

### Question 5  

```{r}
# Setting up an empty workflow
lm_workflow <- workflow() %>%
  # Adding the model
  add_model(lm_model) %>%
  # Adding the recipe
  add_recipe(abalone_recipe)
```

### Question 6   

```{r}
# Fitting the model to the training set
lm_fit <- fit(lm_workflow, abalone_train2)
lm_fit %>%
  extract_fit_parsnip() %>%
  tidy()
```

### Question 7   

```{r}
library(yardstick)

# Creating metric set
abalone_metrics <- metric_set(rmse, rsq, mae)
abalone_metrics

# Creating tibble of model's predicted values from the training data with actual observed ages
abalone_tibble <- predict(lm_fit, new_data = abalone_train2 %>% select(-age))
abalone_tibble <- bind_cols(abalone_tibble, abalone_train2 %>% 
                              select(age))
head(abalone_tibble)

# Applying metric set to tibble
abalone_tibble_metrics <- abalone_metrics(abalone_tibble, truth = age, estimate = .pred)
abalone_tibble_metrics
```

**Results:**  
The RMSE is about 2.202264, the $R^2$ value is about 0.536678, and the MAE is about 1.588166. An $R^2$ value of 0.536678 means that about 53.67% of the variation in `age` is explained by the predictors.  







